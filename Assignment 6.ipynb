{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb15fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "       ip  app  device  os  channel           click_time      attributed_time  \\\n",
      "0   89489    3       1  13      379  2017-11-06 15:13:23                  NaN   \n",
      "1  204158   35       1  13       21  2017-11-06 15:41:07  2017-11-07 08:17:19   \n",
      "2    3437    6       1  13      459  2017-11-06 15:42:32                  NaN   \n",
      "3  167543    3       1  13      379  2017-11-06 15:56:17                  NaN   \n",
      "4  147509    3       1  13      379  2017-11-06 15:57:01                  NaN   \n",
      "\n",
      "   is_attributed  \n",
      "0              0  \n",
      "1              1  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "\n",
      "Summary of the dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2300561 entries, 0 to 2300560\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Dtype \n",
      "---  ------           ----- \n",
      " 0   ip               int64 \n",
      " 1   app              int64 \n",
      " 2   device           int64 \n",
      " 3   os               int64 \n",
      " 4   channel          int64 \n",
      " 5   click_time       object\n",
      " 6   attributed_time  object\n",
      " 7   is_attributed    int64 \n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 140.4+ MB\n",
      "None\n",
      "\n",
      "Missing values in the dataset:\n",
      "ip                       0\n",
      "app                      0\n",
      "device                   0\n",
      "os                       0\n",
      "channel                  0\n",
      "click_time               0\n",
      "attributed_time    1843715\n",
      "is_attributed            0\n",
      "dtype: int64\n",
      "\n",
      "First few rows after feature engineering:\n",
      "       ip  app  device  os  channel  is_attributed  hour  day  dayofweek\n",
      "0   89489    3       1  13      379              0    15    6          0\n",
      "1  204158   35       1  13       21              1    15    6          0\n",
      "2    3437    6       1  13      459              0    15    6          0\n",
      "3  167543    3       1  13      379              0    15    6          0\n",
      "4  147509    3       1  13      379              0    15    6          0\n",
      "\n",
      "Shapes of the training and test sets:\n",
      "X_train: (1840448, 8), X_test: (460113, 8)\n",
      "y_train: (1840448,), y_test: (460113,)\n",
      "\n",
      "Training the model...\n",
      "\n",
      "Predicting on the test set...\n",
      "\n",
      "Model accuracy: 0.9496\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('train_sample.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Display the summary of the dataset\n",
    "print(\"\\nSummary of the dataset:\")\n",
    "print(data.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in the dataset:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Replace placeholders with NaN\n",
    "data.replace(['-', '?'], np.nan, inplace=True)\n",
    "\n",
    "# Convert click_time and attributed_time to datetime\n",
    "data['click_time'] = pd.to_datetime(data['click_time'])\n",
    "data['attributed_time'] = pd.to_datetime(data['attributed_time'], errors='coerce')\n",
    "\n",
    "# Extracting features from click_time\n",
    "data['hour'] = data['click_time'].dt.hour\n",
    "data['day'] = data['click_time'].dt.day\n",
    "data['dayofweek'] = data['click_time'].dt.dayofweek\n",
    "\n",
    "# Drop click_time and attributed_time as they are no longer needed\n",
    "data.drop(columns=['click_time', 'attributed_time'], inplace=True)\n",
    "\n",
    "# Display the first few rows after feature engineering\n",
    "print(\"\\nFirst few rows after feature engineering:\")\n",
    "print(data.head())\n",
    "\n",
    "# Define the features and target\n",
    "X = data.drop(columns=['is_attributed'])\n",
    "y = data['is_attributed']\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shapes of the training and test sets\n",
    "print(\"\\nShapes of the training and test sets:\")\n",
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "# Build the model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining the model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "print(\"\\nPredicting on the test set...\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'\\nModel accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56631dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
